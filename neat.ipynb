{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2\n",
      "0    2\n",
      "6    1\n",
      "5    1\n",
      "4    1\n",
      "3    1\n",
      "2    1\n",
      "dtype: int64\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "{'a': 0, 'b': 1, 'c': 2, 'z': 3, 'g': 4, 'i': 5, 't': 6}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3_test2</th>\n",
       "      <th>col5_bas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col4</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87.0</th>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999.0</th>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999.0</th>\n",
       "      <td>6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        col1  col2  col3_test2  col5_bas\n",
       "col4                                    \n",
       "5.0        1  11.0           0         1\n",
       "3.0        2  11.0           0         1\n",
       "6.0        0   9.0           0         0\n",
       "8.0        3   8.0           1         0\n",
       "10.0       4  10.0           0         1\n",
       "14.0       1  11.0           0         0\n",
       "87.0       0  12.0           0         1\n",
       "999.0      5  13.0           1         1\n",
       "9999.0     6  14.0           1         1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from math import ceil\n",
    "\n",
    "# Maybe: Print all of this code into Python \n",
    "# code to be used or not used by others\n",
    "# Probably should keep the function names.\n",
    "class Neat:\n",
    "    \n",
    "    def __init__(self, df, targetY, indexColumns=[]):        \n",
    "        self.df = df        \n",
    "        self.targetY = self._cleanColumnName(targetY)        \n",
    "        self.indexColumns = self._cleanColumnNamesArray(indexColumns)     \n",
    "        self.uniqueTargetYValues = self.df[self.targetY].unique()\n",
    "        self.targetYMappings = {}\n",
    "        self.numberColumns = []\n",
    "        self.categoryColumns = []\n",
    "        self.datetimeColumns = []\n",
    "        self.medians = []\n",
    "        self.lowerBounds = []\n",
    "        self.upperBounds = []\n",
    "        self.uniqueCategoryValues = {}\n",
    "        self.valuesThatMapTo_Other = {}\n",
    "        self.categoryFrequencies = {}\n",
    "        self.targetYFrequencies = {}\n",
    "        self.idealTargetYFrequencies = {}\n",
    "        # TargetY\n",
    "        self._setTargetYMappings()\n",
    "        self._convertTargetYToNumeric()\n",
    "        self._dropNATargetYRows()        \n",
    "        # Column Metadata\n",
    "        self._cleanColumnNamesDF()        \n",
    "        self._setColumnDataTypes()        \n",
    "        # Index\n",
    "        self._dropDuplicatesAndMissingRowsIfIndexIsSpecified()    \n",
    "        self._addIndex()\n",
    "        # Numbers\n",
    "        self._saveMediansAndBounds()\n",
    "        self._fixMissingNumValuesAndInfinity()\n",
    "        self._fixHighLeveragePoints()\n",
    "        # Categories\n",
    "        self._saveUniqueCategoryValues()   \n",
    "        self._saveCategoryFrequenciesAndValuesThatMapTo_Other()\n",
    "        self._dropCategoryColumnsWithAllMissingValues()\n",
    "        self._fixMissingCategoryValuesAndMapValuesTo_Other()\n",
    "        self._applyDummyEncoding()\n",
    "        # Datetimes\n",
    "        self._dropColumnsWithMissingDatetimeValues()\n",
    "        self._convertDatetimeToNumber()\n",
    "        # Class Imbalance\n",
    "        self._saveTargetYFrequencies()\n",
    "        self._saveIdealTargetYFrequencies()\n",
    "        self._fixTargetYImbalance()\n",
    "    \n",
    "    def _cleanColumnNamesArray(self, indexColumns):\n",
    "        if type(indexColumns) == str:\n",
    "            indexColumns = [indexColumns]\n",
    "        arr = []\n",
    "        for column in indexColumns:\n",
    "            arr.append(self._cleanColumnName(column))\n",
    "        return arr\n",
    "    \n",
    "    def _cleanColumnName(self, string):\n",
    "        return string.strip().lower().replace(' ', '_')\n",
    "    \n",
    "    ########## TargetY ##########\n",
    "    \n",
    "    def _setTargetYMappings(self):\n",
    "        if self.df[self.targetY].dtype == 'object': # is a string\n",
    "            i = 0      \n",
    "            for value in self.uniqueTargetYValues:\n",
    "                if value != None and value.strip() != \"\":\n",
    "                    self.targetYMappings[value] = i\n",
    "                    i = i + 1\n",
    "\n",
    "    def _convertTargetYToNumeric(self):\n",
    "        if self.df[self.targetY].dtype == 'object': # is a string        \n",
    "            self.df[self.targetY] = self.df[self.targetY].map(self.targetYMappings)\n",
    "    \n",
    "    def _dropNATargetYRows(self):    \n",
    "        rowsToDrop = []\n",
    "        for i, row in self.df.iterrows():    \n",
    "            rowsToDrop.append(i) if np.isnan(row[self.targetY]) else None            \n",
    "        self.df = self.df.drop(self.df.index[rowsToDrop])    \n",
    "    \n",
    "    ########## Column Metadata ##########\n",
    "    \n",
    "    def _cleanColumnNamesDF(self):\n",
    "        self.df.columns = self.df.columns.str.strip().str.lower().str.replace(' ', '_')    \n",
    "        \n",
    "    def _setColumnDataTypes(self):\n",
    "        columns = self.df.columns.values.tolist()\n",
    "        for column in columns:    \n",
    "            if column == self.targetY or column in indexColumns:\n",
    "                pass\n",
    "            elif self.df[column].dtype == 'int64' or self.df[column].dtype == 'float64':\n",
    "                self.numberColumns.append(column)\n",
    "            elif self.df[column].dtype == 'object':\n",
    "                self.categoryColumns.append(column)\n",
    "            else:\n",
    "                self.datetimeColumns.append(column)     \n",
    "    \n",
    "    ########## Index ##########\n",
    "    \n",
    "    def _dropDuplicatesAndMissingRowsIfIndexIsSpecified(self):\n",
    "        rowsToDrop = []\n",
    "        if self.indexColumns != []:\n",
    "            self.df = self.df.drop_duplicates(subset=self.indexColumns)\n",
    "            for i, row in self.df.iterrows(): \n",
    "                for column in self.indexColumns:\n",
    "                    if ((self.df[column].dtype == 'int64' or self.df[column].dtype == 'float64') and (np.isnan(row[column]) or np.isinf(row[column]))) or row[column] == None:\n",
    "                        rowsToDrop.append(i)\n",
    "        self.df = self.df.drop(self.df.index[rowsToDrop])    \n",
    "        \n",
    "    def _addIndex(self):\n",
    "        if self.indexColumns == []:\n",
    "            self.df = self.df.set_index(np.arange(1,len(self.df.index)+1))\n",
    "        else:\n",
    "            self.df = self.df.set_index(self.indexColumns)                    \n",
    "        \n",
    "    ########## Numbers ##########\n",
    "        \n",
    "    def _saveMediansAndBounds(self):        \n",
    "        firstQuantiles = self.df.quantile(.25)\n",
    "        thirdQuantiles = self.df.quantile(.75)\n",
    "        \n",
    "        self.medians = self.df.quantile(.50)\n",
    "        self.lowerBounds = {}\n",
    "        self.upperBounds = {}\n",
    "        for column in self.numberColumns:            \n",
    "            self.lowerBounds[column] = self.medians[column] - 2*(self.medians[column] - firstQuantiles[column])\n",
    "            self.upperBounds[column] = self.medians[column] + 2*(thirdQuantiles[column] - self.medians[column])        \n",
    "        \n",
    "    def _fixMissingNumValuesAndInfinity(self):\n",
    "        self.df = self.df.fillna(self.medians) # optionally: replace self.medians with 0\n",
    "        self.df.replace([np.inf, -np.inf], np.nan)\n",
    "        self.df = self.df.fillna(self.upperBounds)        \n",
    "        \n",
    "    def _fixHighLeveragePoints(self):\n",
    "        for i, row in self.df.iterrows(): \n",
    "            for column in self.numberColumns:\n",
    "                if row[column] > self.upperBounds[column]:\n",
    "                    self.df.at[i, column] = self.upperBounds[column]\n",
    "                if row[column] < self.lowerBounds[column]:\n",
    "                    self.df.at[i, column] = self.lowerBounds[column]\n",
    "      \n",
    "    ########## Categories ##########\n",
    "    \n",
    "    def _saveUniqueCategoryValues(self):        \n",
    "        for column in self.categoryColumns:\n",
    "            self.uniqueCategoryValues[column] = []\n",
    "            for value in self.df[column].unique():\n",
    "                if value == None:\n",
    "                    continue    \n",
    "                self.uniqueCategoryValues[column].append(value)\n",
    "            self.uniqueCategoryValues[column].append('_Other')            \n",
    "            \n",
    "    def _saveCategoryFrequenciesAndValuesThatMapTo_Other(self):\n",
    "        for column in self.categoryColumns: \n",
    "            _otherFrequency = 0\n",
    "            self.valuesThatMapTo_Other[column] = []\n",
    "            frequencyPercentage = pd.value_counts(self.df[column].values, sort=False, normalize=True)\n",
    "            self.categoryFrequencies[column] = {}\n",
    "            for value in self.uniqueCategoryValues[column]: \n",
    "                if value == '_Other':\n",
    "                    continue\n",
    "                elif frequencyPercentage[value] < .05: \n",
    "                    self.valuesThatMapTo_Other[column].append(value)\n",
    "                    _otherFrequency = _otherFrequency + frequencyPercentage[value]\n",
    "                else:\n",
    "                    self.categoryFrequencies[column][value] = frequencyPercentage[value]            \n",
    "            self.categoryFrequencies[column]['_Other'] = _otherFrequency\n",
    "                    \n",
    "    def _dropCategoryColumnsWithAllMissingValues(self):\n",
    "        columnsToRemove = []\n",
    "        for column in self.categoryColumns:\n",
    "            if len(self.uniqueCategoryValues[column]) == 1 and self.uniqueCategoryValues[column][0] == '_Other':\n",
    "                columnsToRemove.append(column)\n",
    "        self._dropCategoryColumns(columnsToRemove)\n",
    "        \n",
    "    def _dropCategoryColumns(self, columnsToRemove):\n",
    "        self.df = self.df.drop(columnsToRemove, 1)         \n",
    "        for column in columnsToRemove:\n",
    "            self.categoryColumns.remove(column) \n",
    "            \n",
    "    def _fixMissingCategoryValuesAndMapValuesTo_Other(self):\n",
    "        for i, row in self.df.iterrows(): \n",
    "            for column in self.categoryColumns:        \n",
    "                if row[column] == None:\n",
    "                    self.df.at[i, column] = self._getRandomCategoryBasedOnFrequencies(column)\n",
    "                elif row[column] in self.valuesThatMapTo_Other[column]:\n",
    "                    self.df.at[i, column] = '_Other'\n",
    "            \n",
    "    def _getRandomCategoryBasedOnFrequencies(self, column):\n",
    "        chosenValue, prevValue, cumulativeProbability = None, None, 0\n",
    "        randomNumber = np.random.uniform(0,1,1)[0]\n",
    "        for value in self.uniqueCategoryValues[column]:\n",
    "            probabilityOfValue, prevValue = self.categoryFrequencies[column][value], value\n",
    "            cumulativeProbability = cumulativeProbability + probabilityOfValue\n",
    "            if cumulativeProbability > randomNumber:\n",
    "                chosenValue = value\n",
    "                break\n",
    "        return prevValue if chosenValue == None else chosenValue            \n",
    "\n",
    "    def _applyDummyEncoding(self): # drop_first => dummy encoding instead of one hot encoding\n",
    "        for column in self.categoryColumns:\n",
    "            self.df = pd.concat([self.df.drop(column, axis=1), pd.get_dummies(self.df[column], prefix=column, drop_first=True)], axis=1)            \n",
    "\n",
    "    ########## Datetimes ##########\n",
    "            \n",
    "    def _dropColumnsWithMissingDatetimeValues(self):\n",
    "        columnsToDrop = []\n",
    "        for i, row in self.df.iterrows(): \n",
    "            for column in self.datetimeColumns:\n",
    "                if pd.isnull(row[column]) or row[column] == None:\n",
    "                    columnsToDrop.append(column)\n",
    "                    break\n",
    "        self.df = self.df.drop(columnsToDrop, axis=1)\n",
    "    \n",
    "    def _convertDatetimeToNumber(self):        \n",
    "        self.df[self.datetimeColumns] = self.df[self.datetimeColumns].apply(pd.to_numeric)                       \n",
    "        \n",
    "    ########## Class Imbalance ##########\n",
    "        \n",
    "    def _saveTargetYFrequencies(self):           \n",
    "        self.targetYFrequencies = pd.value_counts(self.df[self.targetY].values, sort=True, normalize=False)        \n",
    "        \n",
    "    def _saveIdealTargetYFrequencies(self): \n",
    "        maxValue = None\n",
    "        for value in self.uniqueTargetYValues:\n",
    "            if maxValue == None or value > maxValue:\n",
    "                maxValue = value\n",
    "        \n",
    "        minValue = ceil(maxValue / 2)\n",
    "        for value in self.uniqueTargetYValues:\n",
    "            actualFrequency = self.targetYFrequencies[value]\n",
    "            self.idealTargetYFrequencies[value] = minValue if actualFrequency < minValue else actualFrequency\n",
    "        \n",
    "    def _fixTargetYImbalance(self):        \n",
    "        pass\n",
    "    \n",
    "df = pd.DataFrame({'col1': ['a','b','c','a','z','g','b','a','i','t'], 'col2': [None,None,None,9,5,10,11,12,13,14]\n",
    "                  , 'col3': ['test1','test1','test1','test1',None,None,'test1','test1','test2','test2']\n",
    "                  , 'col4': [None, 5, 3 ,6 ,8, 10, 14, 87, 999 ,9999]\n",
    "                  , 'col5': [None,None,None,None,'adsf','bas',None,None,None,None]})                \n",
    "targetY = 'col1'\n",
    "#indexColumns = 'col2'\n",
    "indexColumns = ['col4']\n",
    "\n",
    "neat = Neat(df, targetY, indexColumns)\n",
    "\n",
    "neat.df\n",
    "    \n",
    "print(neat.targetYFrequencies)\n",
    "\n",
    "for value in neat.targetYFrequencies:\n",
    "    print(value)\n",
    "for value in neat.targetYMappings:\n",
    "    print(neat.targetYMappings[value])\n",
    "print(neat.targetYMappings)\n",
    "#print(neat.targetYMappings)\n",
    "neat.df\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['col1', 'col2']\n",
      "['col1', 'col2']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'col1': [1,1, 2,3,4,5], 'col2': [3, 3,None, None, None,None]})\n",
    "df\n",
    "df.columns.values.tolist()\n",
    "df.dtypes\n",
    "\n",
    "    \n",
    "       \n",
    "        \n",
    "print(numberColumns)        \n",
    "print(categoryColumns)        \n",
    "print(datetimeColumns)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1    1.5\n",
      "col2    3.0\n",
      "Name: 0.5, dtype: float64\n",
      "A\n",
      "   col1  col2\n",
      "0   1.0   2.0\n",
      "1   2.0   4.0\n",
      "2   1.5   3.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'col1': [1,2,None],'col2': [2,4,None]})\n",
    "#print(df)\n",
    "\n",
    "\n",
    "#print(df.quantile(.25))\n",
    "#print(df.quantile(.5))\n",
    "#print(df.quantile(.75))\n",
    "print(df.quantile(.5))\n",
    "\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"A\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(2.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1     6.0\n",
       "col2    11.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1    4.5\n",
      "col2    9.5\n",
      "Name: 0.25, dtype: float64\n",
      "col1     6.0\n",
      "col2    11.0\n",
      "Name: 0.5, dtype: float64\n",
      "10.5\n",
      "20.5\n"
     ]
    }
   ],
   "source": [
    "quantile1 = df.quantile(.25)\n",
    "quantile3 = df.quantile(.75)\n",
    "\n",
    "\n",
    "medians = df.quantile(.50)\n",
    "print(quantile1)\n",
    "print(medians)\n",
    "\n",
    "# for col in medians:\n",
    "#     print(col)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [\"a\"]\n",
    "if a == []:\n",
    "    print(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(['a'])\n",
    "type('a')==str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0     1   0.0\n",
       "1     1   1.0\n",
       "2     2   NaN\n",
       "3     3   NaN\n",
       "4     4   NaN\n",
       "5     5   NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'col1': [1,1, 2,3,4,5], 'col2': ['a', 'b',None, None, None,None]})\n",
    "\n",
    "# for cat in ['col2','col1']:\n",
    "#     print(\"Levels for catgeory '{0}': {1}\".format(cat, df[cat].unique()))\n",
    "\n",
    "# df['col2']=df['col2'].map({'a':0,'b':1})\n",
    "\n",
    "# df_class = df['col2'].values\n",
    "# df_class\n",
    "\n",
    "# for cat in ['col2']:\n",
    "#     print(cat)\n",
    "    \n",
    "i = 0\n",
    "targetMappings = {}\n",
    "for value in df['col2'].unique():\n",
    "    if value != None and value.strip() != \"\":\n",
    "        targetMappings[value] = i\n",
    "        i = i + 1\n",
    "print(targetMappings)\n",
    "\n",
    "\n",
    "df['col2'] = df['col2'].map(targetMappings)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "a\n",
      "b\n",
      "c\n",
      "0.333333333333\n",
      "float64\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'col1': [5,None,None,None,None,None], 'col2': ['a','a','b','b','b','c']})\n",
    "uniqueCategoryValues = {}\n",
    "categoryFrequencies = {}\n",
    "# rowsToDrop = []\n",
    "# for i, row in df.iterrows():    \n",
    "#     rowsToDrop.append(i) if np.isnan(row['col2']) else None            \n",
    "# df = df.drop(df.index[rowsToDrop])\n",
    "# df\n",
    "# a = 'col2'\n",
    "#print(df.a.value_counts(normalize=True))\n",
    "#print(pd.value_counts(df['col3'].values, sort=False, normalize=True))\n",
    "uniqueCategoryValues['col2'] = df['col2'].unique()\n",
    "#print(uniqueCategoryValues)\n",
    "categoryFrequencies['col2'] = pd.value_counts(df['col2'].values, sort=False, normalize=True)\n",
    "#print(categoryFrequencies['col2']['a'])\n",
    "print(len(uniqueCategoryValues['col2']))\n",
    "uniqueCategoryValues['col2'][0]\n",
    "uniqueCategoryValues['col2']\n",
    "for value in uniqueCategoryValues['col2']:\n",
    "    if value == None:\n",
    "        continue\n",
    "    print(value)\n",
    "print(categoryFrequencies['col2']['a'])\n",
    "categoryFrequencies\n",
    "\n",
    "columns = df.columns.values.tolist()  \n",
    "columns\n",
    "for column in columns:\n",
    "    print(df[column].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.33333333333333331, 'b': 0.5, 'c': 0.16666666666666666}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.value_counts(df['col2'].values, sort=False, normalize=True)\n",
    "\n",
    "\n",
    "categoryFrequencies['col2'] = {}\n",
    "for value in uniqueCategoryValues['col2']:\n",
    "    if value == None:\n",
    "        continue    \n",
    "    categoryFrequencies['col2'][value] = counts[value]\n",
    "        \n",
    "categoryFrequencies['col2']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fb08e7838951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'col2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "for value in df['col2'].unique():\n",
    "    print(value)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e430eeb19f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexColumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'int64'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'float64'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "columns = df.columns.values.tolist()\n",
    "for column in columns:    \n",
    "    if column == self.targetY or column in indexColumns:\n",
    "        pass\n",
    "    elif self.df[column].dtype == 'int64' or self.df[column].dtype == 'float64':\n",
    "        self.numberColumns.append(column)\n",
    "    elif df[column].dtype == 'object':\n",
    "        self.categoryColumns.append(column)\n",
    "    else:\n",
    "        self.datetimeColumns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2_c\n",
       "0     1       0\n",
       "1     2       0\n",
       "2     4       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "df = pd.DataFrame({'col1': [5,None,None,None,None,None], 'col2': ['a','a','b','b','b','c']})\n",
    "df2 = pd.DataFrame({'col1': [1,2,4], 'col2': ['b','b','c']})\n",
    "#enc = preprocessing.OneHotEncoder()\n",
    "#enc.fit()\n",
    "#enc.fit(df2['col1'])\n",
    "\n",
    "# df2 = pd.concat(\n",
    "#     [\n",
    "#         df2,\n",
    "#         pd.get_dummies(df2['col2'], prefix='col2', drop_first=True)\n",
    "\n",
    "\n",
    "df2 = pd.concat([df2.drop('col2', axis=1), pd.get_dummies(df2['col2'], prefix='col2', drop_first=True)], axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    datetime  datetime2\n",
      "0 2015-02-04 2015-02-04\n",
      "1 2016-03-05 2016-03-05\n",
      "2 2018-04-06 2018-04-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>datetime2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1423008000000000000</td>\n",
       "      <td>1423008000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1457136000000000000</td>\n",
       "      <td>1457136000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1522972800000000000</td>\n",
       "      <td>1522972800000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime            datetime2\n",
       "0  1423008000000000000  1423008000000000000\n",
       "1  1457136000000000000  1457136000000000000\n",
       "2  1522972800000000000  1522972800000000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'year': [2015, 2016, 2018],\n",
    "                       'month': [2, 3, 4],\n",
    "                       'day': [4, 5, 6]})\n",
    "datetime = pd.to_datetime(df)\n",
    "df['datetime'] = datetime\n",
    "df['datetime2'] = datetime\n",
    "df = df.drop(['year','month','day'], axis=1)\n",
    "\n",
    "datetimeColumns = ['datetime','datetime2']\n",
    "\n",
    "#df[~df.isnull()] = None\n",
    "print(df.where(df.notnull(), None))\n",
    "\n",
    "\n",
    "columnsToDrop = []\n",
    "for i, row in df.iterrows(): \n",
    "    for column in datetimeColumns:\n",
    "        if row[column] == None or pd.isnull(row[column]):\n",
    "            columnsToDrop.append(column)\n",
    "            break\n",
    "df = df.drop(columnsToDrop,axis=1)\n",
    "\n",
    "#pd.notnull(df['datetime'])\n",
    "df\n",
    "#df\n",
    "\n",
    "#df[df.b.isnull()]\n",
    "\n",
    "\n",
    "df[datetimeColumns] = df[datetimeColumns].apply(pd.to_numeric)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import ceil\n",
    "ceil(2.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
